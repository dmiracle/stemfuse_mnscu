# Module: Big Data Analytics â€“ 1 Credit / 15 hours

Competency: Big Data

Author: Jack Pope 

## Instructor Overview and Objective

This course module is about data analytics in a distributed computing
environment. 

Given that this module is to be worth 1 credit, or 15 hours of
coursework, the instructor should prepare three to five subtopic
discussions. These should account for at least 5 hours of instructional
material and might be in the form of lecture notes or lecture videos.
The additional hours should be comprised of student labs or assignments.
 

The lesson below use the Python (PySpark) and SQL programming languages
on distributed instances of Apache Spark. Installation and configuration
of required software is covered in the Big Data Systems course module.

Students should have prior experience in data structures in the Python
programming language. Experience with SQL and Functional Programming
will also be helpful.

## Table of Contents 

|Unit|Topic
|--|--
|1   | Overview 
|2   | The Map-Reduce Paradigm
|3   | Resilient Distributed Datasets (RDD)
|   | RDD Partitioning
|   | Python Dictionaries Versus RDDs
|4  | Functional Programming
|    | Higher Order Functions
|    | Exercise
|5   | PySpark
|    | Exercise
|    | RDD Persistence
|    | Shared Variables
|    | Exercise
|6  |Spark SQL
|   |Exercise
|7 | Spark Applications

## Other Internet Resources

<https://www.usenix.org/legacy/event/hotpar10/tech/full_papers/McCool.pdf>

<https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf>

<https://spark.apache.org/docs/latest/api/java/org/apache/spark/rdd/RDD.html>

<https://spark.apache.org/docs/latest/api>

PySpark API docs:
<https://spark.apache.org/docs/2.3.1/api/python/index.html>